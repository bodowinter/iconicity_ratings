---
title: "Bayesian model computation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This markdown computes the Bayesian models that underlie the main analysis file "substantive_analysis.Rmd".

## Data and package loading

Load packages:

```{r, warning = FALSE, message = FALSE}
library(brms)
library(car) # for variance inflation factors
library(tidyverse)
```

For reproducibility:

```{r}
packageVersion('brms')
packageVersion('car')
packageVersion('tidyverse')
R.Version()$version.string
```

Load iconicity ratings:

```{r, warning = FALSE, message = FALSE}
icon <- read_csv('../ratings/iconicity_ratings.csv')
```

Load additional datasets:

```{r, warning = FALSE, message = FALSE}
# Data for replications:

SER <- read_csv('../additional_data/juhasz_yap_2013_SER.csv')
AOA <- read_csv('../additional_data/kuperman_2012_AOA.csv')
lanc <- read_csv('../additional_data/lancaster_sensorimotor_norms_2019.csv')
SUBTL <- read_csv('../additional_data/brysbaert_2012_SUBTLEX_POS.csv')
humor <- read_csv('../additional_data/engelthaler_hills_2018_humor.csv')
ding <- read_csv('../additional_data/dingemanse_thompson_2020.csv')
ARC <- read_csv('../additional_data/shaoul_westbury_2010_ARC.csv')
conc <- read_csv('../additional_data/brysbaert_2014_concreteness.csv')
pex <- read_delim('../additional_data/pexman_concreteness_SDT.txt',
                  delim = '\t')
semD <- read_csv('../additional_data/hoffman_2012_semD.csv')

# Data for controlling morphology:

ELP <- read_csv('../additional_data/balota_2007_ELP.csv')

# Data for new analyses:

amsel <- read_csv('../additional_data/amsel_2012_SER.csv')
wisc <- read_csv('../additional_data/wisconsin_2005_norms.csv')
levin <- read_csv('../additional_data/levin_1991_verb_classes.csv')
```

Rename folders and simplify data frames to include only relevant info. Also make Lancaster norm Word column lowercase. Log10 transform SUBTLEX frequencies and contextual diversity:

```{r}
# Age-of-acquisition data:

AOA <- AOA %>% select(Word, Rating.Mean) %>% 
  rename(AOA = Rating.Mean)

# Sensory experience ratings:

SER <- select(SER, Word, SER)

# Pexman et al. (2017):

pex <- select(pex, Word, RTclean_mean, ACC, Concrete_rating)

# Hoffman et al. (2012) semantic diversity:

semD <- semD %>% rename(word = `!term`) %>% 
  select(word, SemD)

# Concreteness ratings:

conc <- select(conc, Word, Conc.M) %>% 
  rename(conc = Conc.M)

# Lancaster sensorimotor norms:

lanc <- lanc %>%
  mutate(Word = str_to_lower(Word)) %>% 
  select(Word:Visual.mean, Dominant.perceptual,
         Max_strength.perceptual,
         Exclusivity.perceptual) %>% 
  rename(Aud = Auditory.mean,
         Gus = Gustatory.mean,
         Hap = Haptic.mean,
         Int = Interoceptive.mean,
         Olf = Olfactory.mean,
         Vis = Visual.mean,
         Mod = Dominant.perceptual,
         Max_perceptual = Max_strength.perceptual,
         Excl = Exclusivity.perceptual)

# Frequency, contextual diversity, and part-of-speech:

SUBTL <- SUBTL %>% 
  rename(Freq = FREQcount,
         CD = CDcount,
         POS = Dom_PoS_SUBTLEX) %>% 
  select(Word, Freq, CD, POS)

# Playfulness:
  
humor <- select(humor, word, mean) %>%
  rename(humor = mean)

# Dingemanse & Thompson (2020) data:

ding <- select(ding, logletterfreq, word, ico_imputed, ico_imputed_monomorph)

# ARC data:

ARC <- ARC %>% mutate(WORD = str_to_lower(WORD)) %>% 
  rename(word = 'WORD')

# Amsel (2012) and Wisconsin (2005) data:

amsel <- select(amsel, Concept, Smell, Color, Taste, Sound, Motion) %>% 
  rename(amsel_smell = Smell, amsel_color = Color,
         amsel_taste = Taste, amsel_sound = Sound,
         amsel_motion = Motion)
wisc <- select(wisc, Word, SoundMean, ColorMean, MotionMean) %>%
  rename(wisc_sound = SoundMean, wisc_color = ColorMean, wisc_motion = MotionMean)


# ELP data:

ELP <- select(ELP, Word, NMorph) %>% 
  mutate(LogMorph = log10(NMorph),
         Word = str_to_lower(Word))
```

Join them into the main iconicity data file:

```{r}
icon <- left_join(icon, conc, by = c('word' = 'Word'))
icon <- left_join(icon, SER, by = c('word' = 'Word'))
icon <- left_join(icon, pex, by = c('word' = 'Word'))
icon <- left_join(icon, semD, by = c('word' = 'word'))
icon <- left_join(icon, AOA, by = c('word' = 'Word'))
icon <- left_join(icon, SUBTL, by = c('word' = 'Word'))
icon <- left_join(icon, humor, by = c('word' = 'word'))
icon <- left_join(icon, lanc, by = c('word' = 'Word'))
icon <- left_join(icon, ding, by = c('word' = 'word'))
icon <- left_join(icon, ARC, by = c('word' = 'word'))
icon <- left_join(icon, wisc, by = c('word' = 'Word'))
icon <- left_join(icon, amsel, by = c('word' = 'Concept'))
icon <- left_join(icon, ELP, by = c('word' = 'Word'))
```

For SUBTLEX, an NA is a true zero:

```{r}
icon <- mutate(icon,
               Freq = ifelse(is.na(Freq), 0, Freq),
               CD = ifelse(is.na(CD), 0, CD))
```

Log-transform the frequencies:

```{r}
icon <- mutate(icon,
               LogFreq = log10(Freq + 1),
               LogCD = log10(CD + 1))
```

Z-score all variables:

```{r}
z_score <- function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)

icon <- mutate(icon,
               rating_z = z_score(rating),
               conc_z = z_score(conc),
               SER_z = z_score(SER),
               SemD_z = z_score(SemD),
               AOA_z = z_score(AOA),
               LogFreq_z = z_score(LogFreq),
               LogCD_z = z_score(LogCD),
               humor_z = z_score(humor),
               logletter_z = z_score(logletterfreq),
               lognmorph_z = z_score(LogMorph),
               ARC_z = z_score(ARC),
               
               conc_rating_z = z_score(Concrete_rating),
               
               amsel_color_z = z_score(amsel_color),
               amsel_smell_z = z_score(amsel_smell),
               amsel_taste_z = z_score(amsel_taste),
               amsel_sound_z = z_score(amsel_sound),
               amsel_motion_z = z_score(amsel_motion),
               
               wisc_sound_z = z_score(wisc_sound),
               wisc_color_z = z_score(wisc_color),
               wisc_motion_z = z_score(wisc_motion),
               
               # Lancaster norms:
               Aud_z = z_score(Aud),
               Gus_z = z_score(Gus),
               Hap_z = z_score(Hap),
               Int_z = z_score(Int),
               Olf_z = z_score(Olf),
               Vis_z = z_score(Vis),
               Max_z = z_score(Max_perceptual),
               Excl_z = z_score(Excl))
```

## Process part of speech tags

Process the part-of-speech information to collapse categories for better representation. First show what categories there are:

```{r}
sort(table(icon$POS))
```

Define vector of stuff to set as function words. "Ex" = there. "#N/A" are words like "gonna", "wanna". 

```{r}
gram <- c('#N/A', 'Article', 'Conjunction',
          'Determiner', 'Not', 'Number',
          'Preposition', 'Pronoun', 'To',
          'Ex')
```

Set this to function words in a new POS variable:

```{r}
icon <- mutate(icon,
               POS_simple = ifelse(POS %in% gram, 'function', POS),
               POS_simple = ifelse(POS_simple == 'Unclassified',
                                   NA, POS_simple),
               POS_simple = ifelse(POS_simple == 'Name',
                                   NA, POS_simple))
```

Check categories:

```{r}
table(icon$POS_simple)
```

Get a reduced POS data frame without names and unclassifieds. This will be used later to making computing averages easier.

```{r}
icon_POS <- filter(icon,
                   !POS_simple %in% c('Unclassified', 'Name'))
```

Check:

```{r}
table(icon_POS$POS_simple)
```

Make function the reference level for analysis below:

```{r}
icon_POS <- mutate(icon_POS,
                   POS_simple = factor(POS_simple),
                   POS_simple = relevel(POS_simple, ref = 'function'))
```

## Bayesian regression settings for all analyses

These settings will be carried through. First, options for parallel processing to use all cores from the respective computer:

```{r}
options(mc.cores=parallel::detectCores())
```

Weakly informative priors on slope coefficient:

```{r}
priors <- c(prior(normal(0, 1), class = b))
```

For MCMC settings (will be used only for models that find it hard to converge):

```{r}
mcmc_controls <- list(adapt_delta = 0.999,
                      max_treedepth = 13)
```

We will convert the SDs to the range 0 to 1. I used this as a guide:

https://stackoverflow.com/questions/929103/convert-a-number-range-to-another-range-maintaining-ratio

```{r}
# mins and maxes:

sd_min <- min(icon$rating_sd)
sd_max <- max(icon$rating_sd)

# convert:

icon <- mutate(icon,
               w = (rating_sd - sd_min) / (sd_max - sd_min),
               
               # to invert (so that max SD = lowest weight):
               w = w * -1 + 1,
               
               # renormalize these weights to have mean 1:
               
               w = w / mean(w))

# check:

mean(icon$w)
arrange(icon, desc(w))
arrange(icon, w)
```

## Compute models for separate analysis

Regressing iconicity ratings onto morphology:

```{r, warning = FALSE, message = FALSE}
morph_mdl <- brm(rating | weights(w) ~ NMorph,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(morph_mdl, file = '../models/morph_mdl.RData')
```

Compare to logmorph model:

```{r, warning = FALSE, message = FALSE}
logmorph_mdl <- brm(rating | weights(w) ~ lognmorph_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(logmorph_mdl, file = '../models/logmorph_mdl.RData')
```

Regressing iconicity ratings onto concreteness ratings:

```{r, warning = FALSE, message = FALSE}
conc_mdl <- brm(rating | weights(w) ~ conc_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(conc_mdl, file = '../models/conc_mdl.RData')
```

Regressing iconicity ratings onto sensory experience ratings:

```{r, warning = FALSE, message = FALSE}
SER_mdl <- brm(rating | weights(w) ~ SER_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(SER_mdl, file = '../models/SER_mdl.RData')
```


Replicating the Sidhu & Pexman (2018) analysis - higher ARC = more similar neighbors (Sidhu p.c.):

```{r, warning = FALSE, message = FALSE}
lonely_mdl <- brm(rating | weights(w) ~ SER_z * ARC_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lonely_mdl, file = '../models/lonely_mdl.RData')
```


Regressing iconicity ratings onto age of acquisition ratings:

```{r, warning = FALSE, message = FALSE}
AOA_mdl <- brm(rating | weights(w) ~ AOA_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(AOA_mdl, file = '../models/AOA_mdl.RData')
```


Regressing iconicity ratings onto frequency and CD controlling for each other:

```{r, warning = FALSE, message = FALSE}
# Frequency model:

freq_mdl <- brm(rating | weights(w) ~ LogFreq_z,
                data = icon,
                
                prior = priors,
               
                # MCMC settings:
                seed = 666,
                cores = 4, init = 0,
                warmup = 2000, iter = 4000, chains = 4)

# Contextual diversity model:

CD_mdl <- brm(rating | weights(w) ~ LogCD_z,
                data = icon,
                
                prior = priors,
               
                # MCMC settings:
                seed = 666,
                cores = 4, init = 0,
                warmup = 2000, iter = 4000, chains = 4)

# Contextual diversity and frequency model:

freq_CD_mdl <- brm(rating | weights(w) ~ LogFreq_z + LogCD_z,
                data = icon,
                
                prior = priors,
               
                # MCMC settings:
                seed = 666,
                cores = 4, init = 0,
                warmup = 2000, iter = 4000, chains = 4)

# Save:

save(freq_mdl, file = '../models/freq_mdl.RData')
save(CD_mdl, file = '../models/CD_mdl.RData')
save(freq_CD_mdl, file = '../models/freq_CD_mdl.RData')
```

Check collinearity for frequency and CD:

```{r}
with(icon, cor(LogFreq, LogCD, use = 'complete.obs'))

# Variance inflation factors:

vif(lm(rating ~ LogFreq + LogCD, data = icon))
```

Regression iconicity on POS. For the POS model it makes sense to do an omnibus "test" of part-of-speech since it is a predictor with multiple levels. For this we need to build the corresponding null model:

```{r}
# POS model:

POS_mdl <- brm(rating | weights(w) ~ POS_simple,
               data = icon_POS,
               
               prior = priors,

                # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# POS null model:

POS_null <- brm(rating | weights(w) ~ 1,
                data = icon_POS,

                # MCMC settings:
                seed = 666,
                cores = 4, init = 0,
                warmup = 2000, iter = 4000, chains = 4)

# Save:

save(POS_mdl, file = '../models/POS_mdl.RData')
save(POS_null, file = '../models/POS_null.RData')
```

The Lupyan & Winter (2018) CD model, but reversed:

```{r}
lupyan_CD_mdl <- brm(LogCD ~ rating_z + conc_z + POS_simple,
                     data = icon_POS,

                     # MCMC settings:
                     seed = 666,
                     cores = 4, init = 0,
                     warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lupyan_CD_mdl, file = '../models/lupyan_CD_mdl.RData')
```

The Lupyan & Winter (2018) semD model:

```{r}
lupyan_semD_mdl <- brm(SemD ~ rating_z + POS_simple + LogFreq_z,
                     data = icon_POS,

                     # MCMC settings:
                     seed = 666,
                     cores = 4, init = 0,
                     warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lupyan_semD_mdl, file = '../models/lupyan_semD_mdl.RData')
```

The Lupyan & Winter (2018) semD model with concreteness:

```{r}
lupyan_semD_conc_mdl <- brm(SemD ~ rating_z + POS_simple +
                              LogFreq_z + conc_z,
                     data = icon_POS,

                     # MCMC settings:
                     seed = 666,
                     cores = 4, init = 0,
                     warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lupyan_semD_conc_mdl, file = '../models/lupyan_semD_conc_mdl.RData')
```

Lupyan & Winter (2018) re-analysis of Pexman et al. (2017) data:

```{r}
lupyan_pex_mdl <- brm(ACC ~ RTclean_mean + rating_z * conc_rating_z +
                        LogFreq + POS_simple,
                      data = icon_POS,
                      
                      # MCMC settings:
                      seed = 666,
                      cores = 4, init = 0,
                      warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lupyan_pex_mdl, file = '../models/lupyan_pex_mdl.RData')
```

Regressing iconicity ratings onto humor ratings:

```{r, warning = FALSE, message = FALSE}
humor_mdl <- brm(rating | weights(w) ~ humor_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(humor_mdl, file = '../models/humor_mdl.RData')
```

Regressing iconicity ratings onto log letter frequencies:

```{r, warning = FALSE, message = FALSE}
logletter_mdl <- brm(rating | weights(w) ~ logletter_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(logletter_mdl, file = '../models/logletter_mdl.RData')
```

Regressing iconicity ratings onto Lancaster sensory modality ratings:

```{r, warning = FALSE, message = FALSE}
lanc_mdl <- brm(rating | weights(w) ~ Aud_z + Gus_z + Hap_z +
                   Int_z + Olf_z + Vis_z +
                  Max_perceptual_z + Excl_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lanc_mdl, file = '../models/lanc_mdl.RData')
```

Check collinearity:

```{r}
vif(lm(rating ~ Aud_z + Gus_z + Hap_z +
               Int_z + Olf_z + Vis_z + Excl_z +
         Max_perceptual_z, data = icon))
```

High, but not nearly as rampant as in the case of CD and frequency.

Get the 80th percentile subset:

```{r}
sense <- icon %>% filter(!is.na(Max_perceptual)) %>% 
  filter(Max_perceptual > quantile(Max_perceptual, 0.8))

# How many?

nrow(sense)
```

Re-do the analysis for the 80th percentile most maximal senses:

```{r}
lanc_80_mdl <- brm(rating | weights(w) ~ Aud_z + Gus_z + Hap_z +
                   Int_z + Olf_z + Vis_z + Excl_z,
               data = sense,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lanc_80_mdl, file = '../models/lanc_80_mdl.RData')
```

Do a model with interaction with perceptual strength:

```{r, warning = FALSE, message = FALSE}
lanc_max_mdl <- brm(rating | weights(w) ~ (Aud_z + Gus_z + Hap_z +
                   Int_z + Olf_z + Vis_z) * Max_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lanc_max_mdl, file = '../models/lanc_max_mdl.RData')
```

## Combined model

Get rid of NAs to check how much overlap there is between all of these:

```{r}
icon_red <- filter(icon_POS,
                   !is.na(SER_z),
                   !is.na(SemD_z),
                   !is.na(AOA_z),
                   !is.na(LogCD_z),
                   !is.na(humor_z),
                   !is.na(logletter_z),
                   !is.na(NMorph))
```

Check:

```{r}
nrow(icon_red)
```

Check concreteness reduced model as alternative:

```{r}
icon_conc <- filter(icon_POS,
                    !is.na(conc_z),
                    !is.na(SemD_z),
                    !is.na(AOA_z),
                    !is.na(LogFreq_z),
                    !is.na(humor_z),
                    !is.na(logletter_z),
                    !is.na(NMorph))
```

Put it all into one model:

```{r, warning = FALSE, message = FALSE}
all_mdl <- brm(rating | weights(w) ~ SER_z + AOA_z + LogCD_z + 
                 humor_z + POS_simple + logletter_z + ARC_z +
                 
                 # Control:
                 
                 NMorph,
               
               data = icon_red,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

all_mdl_no_POS <- brm(rating | weights(w) ~ SER_z + AOA_z + LogCD_z + 
                 humor_z + logletter_z + ARC_z +
                 
                 # Control:
                 
                 NMorph,
               
               data = icon_red,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(all_mdl, file = '../models/all_mdl.RData')
save(all_mdl_no_POS, file = '../models/all_mdl_no_POS.RData')
```

Put it all into one model with concreteness instead:

```{r, warning = FALSE, message = FALSE}
all_conc_mdl <- brm(rating | weights(w) ~ conc_z + AOA_z + LogCD_z + 
                 humor_z + POS_simple + logletter_z + ARC_z +
                 
                 # Control:
                 
                 NMorph,
               
               data = icon_conc,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

all_conc_mdl_no_POS <- brm(rating | weights(w) ~ conc_z + AOA_z +
                             LogCD_z + 
                 humor_z + logletter_z + ARC_z +
                 
                 # Control:
                 
                 NMorph,
               
               data = icon_conc,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(all_conc_mdl, file = '../models/all_conc_mdl.RData')
save(all_conc_mdl_no_POS, file = '../models/all_conc_mdl_no_POS.RData')
```

## New analyses (new data):

Perform analysis of Amsel et al. (2012) and Wisconsin (2005) data.

First Amsel (2012):

```{r}
amsel_mdl <- brm(rating | weights(w) ~ amsel_color_z + amsel_taste_z +
                   amsel_sound_z + amsel_smell_z + amsel_motion_z,
               
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(amsel_mdl, file = '../models/amsel_mdl.RData')
```

Second Wisconsin (2005):

```{r}
wisc_mdl <- brm(rating | weights(w) ~ wisc_sound_z + wisc_color_z + wisc_motion_z,
               
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(wisc_mdl, file = '../models/wisc_mdl.RData')
```

Third, Beth Levin verb classes. First merge:

```{r}
levin <- left_join(levin, icon, by = c('verb' = 'word'))
```

Then model:

```{r}
levin_mdl <- brm(rating | weights(w) ~ category,
               
               data = levin,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

levin_null_mdl <- brm(rating | weights(w) ~ 1,
               
               data = levin,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4, init = 0,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(levin_mdl, file = '../models/levin_mdl.RData')
save(levin_null_mdl, file = '../models/levin_null_mdl.RData')
```

This completes this analysis.

