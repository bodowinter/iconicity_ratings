---
title: "Bayesian models - reduced"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This markdown computes the Bayesian models that underlie the main analysis file "substantive_analysis.Rmd".

## Data and package loading

Load packages:

```{r, warning = FALSE, message = FALSE}
library(brms, quietly = TRUE)
library(car, quietly = TRUE) # for variance inflation factors
library(tidyverse, quietly = TRUE)
```

For reproducibility:

```{r}
packageVersion('brms')
packageVersion('car')
packageVersion('tidyverse')
R.Version()$version.string
```

Load iconicity ratings:

```{r, warning = FALSE, message = FALSE}
icon <- read.csv('../ratings/iconicity_ratings.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
```

Load additional datasets:

```{r, warning = FALSE, message = FALSE}
# Data for replications:

SER <- read.csv('../additional_data/juhasz_yap_2013_SER.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
AOA <- read.csv('../additional_data/kuperman_2012_AOA.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
SUBTL <- read.csv('../additional_data/brysbaert_2012_SUBTLEX_POS.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
humor <- read.csv('../additional_data/engelthaler_hills_2018_humor.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
ding <- read.csv('../additional_data/dingemanse_thompson_2020.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
ARC <- read.csv('../additional_data/shaoul_westbury_2010_ARC.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
conc <- read.csv('../additional_data/brysbaert_2014_concreteness.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
```

Rename folders and simplify data frames to include only relevant info. Also make Lancaster norm Word column lowercase. Log10 transform SUBTLEX frequencies and contextual diversity:

```{r}
# Age-of-acquisition data:

AOA <- AOA %>% select(Word, Rating.Mean) %>% 
  rename(AOA = Rating.Mean)

# Sensory experience ratings:

SER <- select(SER, Word, SER)

# Concreteness ratings:

conc <- select(conc, Word, Conc.M) %>% 
  rename(conc = Conc.M)

# Frequency, contextual diversity, and part-of-speech:

SUBTL <- SUBTL %>% 
  rename(Freq = FREQcount,
         CD = CDcount,
         POS = Dom_PoS_SUBTLEX) %>% 
  select(Word, Freq, CD, POS)

# Playfulness:
  
humor <- select(humor, word, mean) %>%
  rename(humor = mean)

# Dingemanse & Thompson (2020) data:

ding <- select(ding, logletterfreq, word, ico_imputed, ico_imputed_monomorph)

# ARC data:

ARC <- ARC %>% mutate(WORD = str_to_lower(WORD)) %>% 
  rename(word = 'WORD')
```

Join them into the main iconicity data file:

```{r}
icon <- left_join(icon, conc, by = c('word' = 'Word'))
icon <- left_join(icon, SER, by = c('word' = 'Word'))
icon <- left_join(icon, AOA, by = c('word' = 'Word'))
icon <- left_join(icon, SUBTL, by = c('word' = 'Word'))
icon <- left_join(icon, humor, by = c('word' = 'word'))
icon <- left_join(icon, ding, by = c('word' = 'word'))
icon <- left_join(icon, ARC, by = c('word' = 'word'))
```

For SUBTLEX, an NA is a true zero:

```{r}
icon <- mutate(icon,
               Freq = ifelse(is.na(Freq), 0, Freq))
```

Log-transform the frequencies:

```{r}
icon <- mutate(icon,
               LogFreq = log10(Freq + 1))
```

Z-score all variables:

```{r}
z_score <- function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)

icon <- mutate(icon,
               rating_z = z_score(rating),
               conc_z = z_score(conc),
               SER_z = z_score(SER),
               AOA_z = z_score(AOA),
               LogFreq_z = z_score(LogFreq),
               humor_z = z_score(humor),
               logletter_z = z_score(logletterfreq),
               ARC_z = z_score(ARC))
```

## Process part of speech tags

Process the part-of-speech information to collapse categories for better representation. First show what categories there are:

```{r}
sort(table(icon$POS))
```

Define vector of stuff to set as function words. "Ex" = there. "#N/A" are words like "gonna", "wanna". 

```{r}
gram <- c('#N/A', 'Article', 'Conjunction',
          'Determiner', 'Not', 'Number',
          'Preposition', 'Pronoun', 'To',
          'Ex')
```

Set this to function words in a new POS variable:

```{r}
icon <- mutate(icon,
               POS_simple = ifelse(POS %in% gram, 'function', POS),
               POS_simple = ifelse(POS_simple == 'Unclassified',
                                   NA, POS_simple),
               POS_simple = ifelse(POS_simple == 'Name',
                                   NA, POS_simple))
```

Check categories:

```{r}
table(icon$POS_simple)
```


## Bayesian regression settings for all analyses

These settings will be carried through. First, options for parallel processing to use all cores from the respective computer:

```{r}
options(mc.cores=parallel::detectCores())
```

Weakly informative priors on slope coefficient:

```{r}
priors <- c(prior(normal(0, 0.5), class = b))
```

For MCMC settings (will be used only for models that find it hard to converge):

```{r}
mcmc_controls <- list(adapt_delta = 0.999,
                      max_treedepth = 13)
```

We will convert the SDs to the range 0 to 1. I used this as a guide:

https://stackoverflow.com/questions/929103/convert-a-number-range-to-another-range-maintaining-ratio

```{r}
# mins and maxes:

sd_min <- min(icon$rating_sd, na.rm = TRUE)
sd_max <- max(icon$rating_sd, na.rm = TRUE)

# convert:

icon <- mutate(icon,
               w = (rating_sd - sd_min) / (sd_max - sd_min),
               
               # to invert (so that max SD = lowest weight):
               
               w = w * -1 + 1,
               
               # renormalize these weights to have mean 1:
               
               w = w / mean(w))

# check:

mean(icon$w)
arrange(icon, desc(w))
arrange(icon, w)
```

Get a reduced POS data frame without names and unclassifieds. This will be used later to making computing averages easier.

```{r}
icon_POS <- filter(icon,
                   !POS_simple %in% c('Unclassified', 'Name'))
```

Check:

```{r}
table(icon_POS$POS_simple)
```

Make function the reference level for analysis below:

```{r}
icon_POS <- mutate(icon_POS,
                   POS_simple = factor(POS_simple),
                   POS_simple = relevel(POS_simple, ref = 'function'))
```

## Fit models

Big model that combines everything. Get rid of NAs to check how much overlap there is between all of these:

```{r}
icon_red <- filter(icon_POS,
                   !is.na(conc_z),
                   !is.na(SER_z),
                   !is.na(AOA_z),
                   !is.na(LogFreq_z),
                   !is.na(humor_z),
                   !is.na(logletter_z),
                   !is.na(POS_simple))
```

Check:

```{r}
nrow(icon_red)
```

What's the correlation between concreteness and SER for this dataset?

```{r}
with(icon_red, cor.test(conc_z, SER_z))
```

Not *that* high!

Assess variance inflation factors:

```{r}
mdl_vif <- lm(rating ~ 1 + conc_z + SER_z +
                AOA_z + LogFreq_z + 
                humor_z + POS_simple + logletter_z + ARC_z +
                SER_z:ARC_z,
              data = icon_red)

vif(mdl_vif)
```

They are fine actually!

Put it all into one model:

```{r all_mdl, warning = FALSE, message = FALSE}
all_mdl <- brm(rating | weights(w) ~ 1 + conc_z + SER_z +
                 AOA_z + LogFreq_z + 
                 humor_z + POS_simple + logletter_z + ARC_z +
                 SER_z:ARC_z,
               
               data = icon_red,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(all_mdl, file = '../models/all_mdl.RData')
```

Do the one without POS:

```{r}
all_mdl_no_POS <- brm(rating | weights(w) ~ 1 + conc_z + SER_z +
                        AOA_z + LogFreq_z + 
                 humor_z + logletter_z + ARC_z,
               
               data = icon_red,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

# Save:
save(all_mdl_no_POS, file = '../models/all_mdl_no_POS.RData')
```

Get the LOO-CV:

```{r loo_compare}
all_loo <- loo(all_mdl)
all_no_POS_loo <- loo(all_mdl_no_POS)

# Comparison and save:

loo_comp <- loo_compare(all_no_POS_loo, all_loo)
save(loo_comp, file = '../models/all_loo_compare.RData')
```

Put it all into one model without regression weights:

```{r no_weight_mdl, warning = FALSE, message = FALSE}
noweight_mdl <- brm(rating ~ 1 + conc_z + SER_z +
                      AOA_z + LogFreq_z +
                 humor_z + POS_simple + logletter_z + ARC_z +
                 SER_z:ARC_z,
               
               data = icon_red,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(noweight_mdl, file = '../models/noweight_mdl.RData')
```


This completes this analysis.

