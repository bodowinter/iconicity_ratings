---
title: "Bayesian models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This markdown computes the Bayesian models that underlie the main analysis file "substantive_analysis.Rmd".

## Data and package loading

Load packages:

```{r, warning = FALSE, message = FALSE}
library(brms, quietly = TRUE)
library(car, quietly = TRUE) # for variance inflation factors
library(tidyverse, quietly = TRUE)
```

For reproducibility:

```{r}
packageVersion('brms')
packageVersion('car')
packageVersion('tidyverse')
R.Version()$version.string
```

Load iconicity ratings:

```{r, warning = FALSE, message = FALSE}
icon <- read.csv('../ratings/iconicity_ratings.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
```

Load additional datasets:

```{r, warning = FALSE, message = FALSE}
# Data for replications:

SER <- read.csv('../additional_data/juhasz_yap_2013_SER.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
AOA <- read.csv('../additional_data/kuperman_2012_AOA.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
lanc <- read.csv('../additional_data/lancaster_sensorimotor_norms_2019.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
SUBTL <- read.csv('../additional_data/brysbaert_2012_SUBTLEX_POS.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
humor <- read.csv('../additional_data/engelthaler_hills_2018_humor.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
ding <- read.csv('../additional_data/dingemanse_thompson_2020.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
ARC <- read.csv('../additional_data/shaoul_westbury_2010_ARC.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
conc <- read.csv('../additional_data/brysbaert_2014_concreteness.csv',
                stringsAsFactors = FALSE) %>% as_tibble()

# Data for controlling morphology:

ELP <- read.csv('../additional_data/balota_2007_ELP.csv',
                stringsAsFactors = FALSE) %>% as_tibble()

# Data for new analyses:

amsel <- read.csv('../additional_data/amsel_2012_SER.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
wisc <- read.csv('../additional_data/wisconsin_2005_norms.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
levin <- read.csv('../additional_data/levin_1991_verb_classes.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
lup_gen <- read.csv('../additional_data/lupyan_generality.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
```

Rename folders and simplify data frames to include only relevant info. Also make Lancaster norm Word column lowercase. Log10 transform SUBTLEX frequencies and contextual diversity:

```{r}
# Age-of-acquisition data:

AOA <- AOA %>% select(Word, Rating.Mean) %>% 
  rename(AOA = Rating.Mean)

# Sensory experience ratings:

SER <- select(SER, Word, SER)

# Concreteness ratings:

conc <- select(conc, Word, Conc.M) %>% 
  rename(conc = Conc.M)

# Lancaster sensorimotor norms:

lanc <- lanc %>%
  mutate(Word = str_to_lower(Word)) %>% 
  select(Word:Visual.mean, Dominant.perceptual,
         Max_strength.perceptual,
         Exclusivity.perceptual) %>% 
  rename(Aud = Auditory.mean,
         Gus = Gustatory.mean,
         Hap = Haptic.mean,
         Int = Interoceptive.mean,
         Olf = Olfactory.mean,
         Vis = Visual.mean,
         Mod = Dominant.perceptual,
         Max_perceptual = Max_strength.perceptual,
         Excl = Exclusivity.perceptual)

# Frequency, contextual diversity, and part-of-speech:

SUBTL <- SUBTL %>% 
  rename(Freq = FREQcount,
         CD = CDcount,
         POS = Dom_PoS_SUBTLEX) %>% 
  select(Word, Freq, CD, POS)

# Playfulness:
  
humor <- select(humor, word, mean) %>%
  rename(humor = mean)

# Dingemanse & Thompson (2020) data:

ding <- select(ding, logletterfreq, word, ico_imputed, ico_imputed_monomorph)

# ARC data:

ARC <- ARC %>% mutate(WORD = str_to_lower(WORD)) %>% 
  rename(word = 'WORD')

# Amsel (2012) and Wisconsin (2005) data:

amsel <- select(amsel, Concept, Smell, Color, Taste, Sound, Motion) %>% 
  rename(amsel_smell = Smell, amsel_color = Color,
         amsel_taste = Taste, amsel_sound = Sound,
         amsel_motion = Motion)
wisc <- select(wisc, Word, SoundMean, ColorMean, MotionMean) %>%
  rename(wisc_sound = SoundMean, wisc_color = ColorMean, wisc_motion = MotionMean)


# ELP data:

ELP <- select(ELP, Word, NMorph) %>% 
  mutate(LogMorph = log10(NMorph),
         Word = str_to_lower(Word))

# Generality data:

lup_gen <- select(lup_gen, word, generality)
```

Join them into the main iconicity data file:

```{r}
icon <- left_join(icon, conc, by = c('word' = 'Word'))
icon <- left_join(icon, SER, by = c('word' = 'Word'))
icon <- left_join(icon, AOA, by = c('word' = 'Word'))
icon <- left_join(icon, SUBTL, by = c('word' = 'Word'))
icon <- left_join(icon, humor, by = c('word' = 'word'))
icon <- left_join(icon, lanc, by = c('word' = 'Word'))
icon <- left_join(icon, ding, by = c('word' = 'word'))
icon <- left_join(icon, ARC, by = c('word' = 'word'))
icon <- left_join(icon, wisc, by = c('word' = 'Word'))
icon <- left_join(icon, amsel, by = c('word' = 'Concept'))
icon <- left_join(icon, ELP, by = c('word' = 'Word'))
icon <- left_join(icon, lup_gen, by = c('word' = 'word'))
```

For SUBTLEX, an NA is a true zero:

```{r}
icon <- mutate(icon,
               Freq = ifelse(is.na(Freq), 0, Freq),
               CD = ifelse(is.na(CD), 0, CD))
```

Log-transform the frequencies:

```{r}
icon <- mutate(icon,
               LogFreq = log10(Freq + 1),
               LogCD = log10(CD + 1))
```

Z-score all variables:

```{r}
z_score <- function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)

icon <- mutate(icon,
               rating_z = z_score(rating),
               conc_z = z_score(conc),
               SER_z = z_score(SER),
               AOA_z = z_score(AOA),
               LogFreq_z = z_score(LogFreq),
               LogCD_z = z_score(LogCD),
               humor_z = z_score(humor),
               logletter_z = z_score(logletterfreq),
               lognmorph_z = z_score(LogMorph),
               ARC_z = z_score(ARC),
               
               conc_rating_z = z_score(Concrete_rating),
               
               amsel_color_z = z_score(amsel_color),
               amsel_smell_z = z_score(amsel_smell),
               amsel_taste_z = z_score(amsel_taste),
               amsel_sound_z = z_score(amsel_sound),
               amsel_motion_z = z_score(amsel_motion),
               
               wisc_sound_z = z_score(wisc_sound),
               wisc_color_z = z_score(wisc_color),
               wisc_motion_z = z_score(wisc_motion),
               
               # Lancaster norms:
               Aud_z = z_score(Aud),
               Gus_z = z_score(Gus),
               Hap_z = z_score(Hap),
               Int_z = z_score(Int),
               Olf_z = z_score(Olf),
               Vis_z = z_score(Vis),
               Max_z = z_score(Max_perceptual),
               Excl_z = z_score(Excl),
               generality_z = z_score(generality))
```

## Process part of speech tags

Process the part-of-speech information to collapse categories for better representation. First show what categories there are:

```{r}
sort(table(icon$POS))
```

Define vector of stuff to set as function words. "Ex" = there. "#N/A" are words like "gonna", "wanna". 

```{r}
gram <- c('#N/A', 'Article', 'Conjunction',
          'Determiner', 'Not', 'Number',
          'Preposition', 'Pronoun', 'To',
          'Ex')
```

Set this to function words in a new POS variable:

```{r}
icon <- mutate(icon,
               POS_simple = ifelse(POS %in% gram, 'function', POS),
               POS_simple = ifelse(POS_simple == 'Unclassified',
                                   NA, POS_simple),
               POS_simple = ifelse(POS_simple == 'Name',
                                   NA, POS_simple))
```

Check categories:

```{r}
table(icon$POS_simple)
```


## Bayesian regression settings for all analyses

These settings will be carried through. First, options for parallel processing to use all cores from the respective computer:

```{r}
options(mc.cores=parallel::detectCores())
```

Weakly informative priors on slope coefficient:

```{r}
priors <- c(prior(normal(0, 0.5), class = b))
```

For MCMC settings (will be used only for models that find it hard to converge):

```{r}
mcmc_controls <- list(adapt_delta = 0.999,
                      max_treedepth = 13)
```

We will convert the SDs to the range 0 to 1. I used this as a guide:

https://stackoverflow.com/questions/929103/convert-a-number-range-to-another-range-maintaining-ratio

```{r}
# mins and maxes:

sd_min <- min(icon$rating_sd)
sd_max <- max(icon$rating_sd)

# convert:

icon <- mutate(icon,
               w = (rating_sd - sd_min) / (sd_max - sd_min),
               
               # to invert (so that max SD = lowest weight):
               
               w = w * -1 + 1,
               
               # renormalize these weights to have mean 1:
               
               w = w / mean(w))

# check:

mean(icon$w)
arrange(icon, desc(w))
arrange(icon, w)
```

Get a reduced POS data frame without names and unclassifieds. This will be used later to making computing averages easier.

```{r}
icon_POS <- filter(icon,
                   !POS_simple %in% c('Unclassified', 'Name'))
```

Check:

```{r}
table(icon_POS$POS_simple)
```

Make function the reference level for analysis below:

```{r}
icon_POS <- mutate(icon_POS,
                   POS_simple = factor(POS_simple),
                   POS_simple = relevel(POS_simple, ref = 'function'))
```


## Fit models

Regressing iconicity ratings onto Lancaster sensory modality ratings:

```{r, warning = FALSE, message = FALSE}
lanc_mdl <- brm(rating | weights(w) ~ Aud_z + Gus_z + Hap_z +
                   Int_z + Olf_z + Vis_z +
                  Max_z + Excl_z,
               data = icon,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lanc_mdl, file = '../models/lanc_mdl.RData')
```

Check collinearity:

```{r}
vif(lm(rating ~ Aud_z + Gus_z + Hap_z +
               Int_z + Olf_z + Vis_z + Excl_z +
         Max_z, data = icon))
```

High, but should be OK given how much data we have. Get the 80th percentile subset:

```{r}
sense <- icon %>% filter(!is.na(Max_perceptual)) %>% 
  filter(Max_perceptual > quantile(Max_perceptual, 0.8))

# How many?

nrow(sense)
```

Re-do the analysis for the 80th percentile most maximal senses:

```{r}
lanc_80_mdl <- brm(rating | weights(w) ~ Aud_z + Gus_z + Hap_z +
                   Int_z + Olf_z + Vis_z + Excl_z,
               data = sense,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(lanc_80_mdl, file = '../models/lanc_80_mdl.RData')
```

Big model that combines everything. Get rid of NAs to check how much overlap there is between all of these:

```{r}
icon_red <- filter(icon_POS,
                   !is.na(SER_z),
                   !is.na(AOA_z),
                   !is.na(LogFreq_z),
                   !is.na(humor_z),
                   !is.na(logletter_z),
                   !is.na(NMorph),
                   !is.na(POS_simple))
```

Check:

```{r}
nrow(icon_red)
```

Check concreteness reduced model as alternative:

```{r}
icon_conc <- filter(icon_POS,
                    !is.na(conc_z),
                    !is.na(AOA_z),
                    !is.na(LogFreq_z),
                    !is.na(humor_z),
                    !is.na(logletter_z),
                    !is.na(NMorph),
                    !is.na(POS_simple))
```

Put it all into one model:

```{r, warning = FALSE, message = FALSE}
all_mdl <- brm(rating | weights(w) ~ SER_z + AOA_z + LogFreq_z + 
                 humor_z + POS_simple + logletter_z + ARC_z +
                 SER_z:ARC_z,
               
               data = icon_red,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

all_mdl_no_POS <- brm(rating | weights(w) ~ SER_z + AOA_z + LogFreq_z + 
                 humor_z + logletter_z + ARC_z,
               
               data = icon_red,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(all_mdl, file = '../models/all_mdl.RData')
save(all_mdl_no_POS, file = '../models/all_mdl_no_POS.RData')
```

Get the LOO-CV:

```{r}
all_loo <- loo(all_mdl)
all_no_POS_loo <- loo(all_mdl_no_POS)

# Comparison and save:

loo_comp <- loo_compare(all_no_POS_loo, all_loo)
save(loo_comp, file = '../models/all_loo_compare.RData')
```

Put it all into one model with concreteness instead:

```{r, warning = FALSE, message = FALSE}
all_conc_mdl <- brm(rating | weights(w) ~ conc_z + AOA_z + LogCD_z + 
                 humor_z + POS_simple + logletter_z + ARC_z,
               
               data = icon_conc,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)
# Save:

save(all_conc_mdl, file = '../models/all_conc_mdl.RData')
```

Put it all into one model without regression weights:

```{r, warning = FALSE, message = FALSE}
noweight_mdl <- brm(rating ~ SER_z + AOA_z + LogCD_z + 
                 humor_z + POS_simple + logletter_z + ARC_z +
                 SER_z:ARC_z,
               
               data = icon_red,
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(noweight_mdl, file = '../models/noweight_mdl.RData')
```

## New analyses (new data):

Beth Levin verb classes. First merge:

```{r}
levin <- left_join(levin, icon, by = c('verb' = 'word'))
```

Then model:

```{r}
levin_mdl <- brm(rating | weights(w) ~ category + (1|verb),
               data = filter(levin, !is.na(rating)),
               
               prior = priors,
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

levin_null_mdl <- brm(rating | weights(w) ~ 1,
               data = filter(levin, !is.na(rating)),
               
               # MCMC settings:
               seed = 666,
               control = mcmc_controls,
               cores = 4,
               warmup = 2000, iter = 4000, chains = 4)

# Save:

save(levin_mdl, file = '../models/levin_mdl.RData')
save(levin_null_mdl, file = '../models/levin_null_mdl.RData')
```

Perform comparison:

```{r}
levin_loo <- loo(levin_mdl)
levin_null_loo <- loo(levin_null_mdl)

# compare:

levin_loo_compare <- loo_compare(levin_loo, levin_null_loo)
save(levin_loo_compare, file = '../models/levin_loo_compare.RData')
```

This completes this analysis.

