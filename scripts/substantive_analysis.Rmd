---
title: "Iconicity ratings - substantive analysis"
author: "Bodo"
date: "11/03/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This markdown performs a number of different analysis that serve to demonstrate how the iconicity ratings correlate with other psycholinguistic norms that have been collected. In addition, we produce some plots of the data to give an overview of the ratings.

The models are computed in the file `Bayesian_models.Rmd` and will be loaded in and interpreted here.

## Data and package loading

Load packages:

```{r, warning = FALSE, message = FALSE}
library(brms, quietly = TRUE)
library(tidyverse, quietly = TRUE)
library(patchwork, quietly = TRUE)
```

For reproducibility:

```{r}
packageVersion('brms')
packageVersion('tidyverse')
packageVersion('patchwork')
R.Version()$version.string
```

Load iconicity ratings:

```{r, warning = FALSE, message = FALSE}
icon <- read.csv('../ratings/iconicity_ratings.csv')
```

Load additional datasets. Getting "buffer" errors with `read.csv()`, so will use `read.csv()` and `as_tibble()` for now.

```{r, warning = FALSE, message = FALSE}
# Data for replications:

SER <- read.csv('../additional_data/juhasz_yap_2013_SER.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
AOA <- read.csv('../additional_data/kuperman_2012_AOA.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
lanc <- read.csv('../additional_data/lancaster_sensorimotor_norms_2019.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
SUBTL <- read.csv('../additional_data/brysbaert_2012_SUBTLEX_POS.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
humor <- read.csv('../additional_data/engelthaler_hills_2018_humor.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
ding <- read.csv('../additional_data/dingemanse_thompson_2020.csv',
                stringsAsFactors = FALSE) %>% as_tibble()
```

Rename folders and simplify data frames to include only relevant info. Also make Lancaster norm Word column lowercase. Log10 transform SUBTLEX frequencies and contextual diversity:

```{r}
# Age-of-acquisition data:

AOA <- AOA %>% select(Word, Rating.Mean) %>% 
  rename(AOA = Rating.Mean)

# Sensory experience ratings:

SER <- select(SER, Word, SER)

# Frequency, contextual diversity, and part-of-speech:

SUBTL <- SUBTL %>% 
  rename(Freq = FREQcount,
         POS = Dom_PoS_SUBTLEX) %>% 
  select(Word, Freq, POS)

# Playfulness:
  
humor <- select(humor, word, mean) %>%
  rename(humor = mean)

# Dingemanse & Thompson (2020) data:

ding <- select(ding, logletterfreq, word, ico, ico_imputed, ico_imputed_monomorph)
```

Join them into the main iconicity data file:

```{r}
icon <- left_join(icon, SER, by = c('word' = 'Word'))
icon <- left_join(icon, AOA, by = c('word' = 'Word'))
icon <- left_join(icon, SUBTL, by = c('word' = 'Word'))
icon <- left_join(icon, humor, by = c('word' = 'word'))
icon <- left_join(icon, lanc, by = c('word' = 'Word'))
icon <- left_join(icon, ding, by = c('word' = 'word'))
```

For SUBTLEX, an NA is a true zero:

```{r}
icon <- mutate(icon,
               Freq = ifelse(is.na(Freq), 0, Freq))
```

Log-transform the frequencies:

```{r}
icon <- mutate(icon,
               LogFreq = log10(Freq + 1))
```

Z-score all variables:

```{r}
z_score <- function(x) (x - mean(x, na.rm = TRUE)) / sd(x)

icon <- mutate(icon,
               SER_z = z_score(SER),
               AOA_z = z_score(AOA),
               LogFreq_z = z_score(LogFreq),
               humor_z = z_score(humor),
               logletter_z = z_score(logletterfreq))
```

## Process part of speech tags

Process the part-of-speech information to collapse categories for better representation. First show what categories there are:

```{r}
sort(table(icon$POS))
```

Define vector of stuff to set as function words. "Ex" = there. "#N/A" are words like "gonna", "wanna". 

```{r}
gram <- c('#N/A', 'Article', 'Conjunction',
          'Determiner', 'Not', 'Number',
          'Preposition', 'Pronoun', 'To',
          'Ex')
```

Set this to function words in a new POS variable:

```{r}
icon <- mutate(icon,
               POS_simple = ifelse(POS %in% gram, 'Function', POS))
```

Check categories:

```{r}
table(icon$POS_simple)
```

Get a reduced POS data frame without names and unclassifieds. This will be used later to making computing averages easier.

```{r}
icon_POS <- filter(icon,
                   !POS_simple %in% c('Unclassified', 'Name'))
```

Check:

```{r}
table(icon_POS$POS_simple)
```


## Check overlap with different datasets for reporting

How many data points?

```{r}
filter(icon, !is.na(SER)) %>% nrow()
filter(icon, !is.na(AOA)) %>% nrow()
filter(icon, !is.na(humor)) %>% nrow()
```


## Descriptive statistics

Average iconicity for these:

```{r}
icon_POS %>% group_by(POS_simple) %>% 
  summarize(M = mean(rating),
            SD = sd(rating)) %>% 
  arrange(desc(M))
```

Count each one for Table 3.

```{r}
icon_POS %>%
  count(POS_simple)
```


## Correlation table

Get the variables of interest:

```{r}
these_vars <- c("rating", "SER", "AOA", "LogFreq",
                "logletterfreq", "humor")
```

Get these vars and perform pairwise correlations:

```{r}
# Get subset:

df_vars <- icon[, these_vars]

# Correlate and round:

all_corrs <- round(cor(df_vars, use = 'complete.obs'), 2)

# Print and save:

all_corrs
write_csv(as.data.frame(all_corrs), '../tables/all_correlations.csv')
```

## Interpret models

Load all models from the models folder:

```{r}
all_models <- list.files('../models/')

for (i in seq_along(all_models)) {
  load(str_c('../models/', all_models[i]))
}
```

First, let's look at all r-squareds:

```{r}
# FUll model:

bayes_R2(all_mdl)
bayes_R2(all_mdl_no_POS)
bayes_R2(noweight_mdl)
```

Next, let's look at the model summaries:

```{r}
# FUll model:

all_mdl
```

Assess priors:

```{r}
prior_summary(all_mdl)
```

## Make a coefficient plot of the main model

Get the fixed effects:

```{r}
these_rows <- row.names(fixef(all_mdl))
fixefs <- as_tibble(fixef(all_mdl))
fixefs$variable <- these_rows

# Get rid of intercept:

fixefs <- fixefs[-1, ]

# Get rid of the POS predictors for the plot:

POS <- c('POS_simpleAdjective', 'POS_simpleAdverb',
         'POS_simpleInterjection', 'POS_simpleNoun',
         'POS_simpleVerb')
fixefs <- filter(fixefs,
                 !(variable %in% POS))

# Rename the variables:

fixefs <- mutate(fixefs,
                 variable = str_remove(variable, '_z'),
                 variable = ifelse(variable == 'humor',
                                   'humor ratings', variable),
                 variable = ifelse(variable == 'LogFreq',
                                   'log frequency', variable),
                 variable = ifelse(variable == 'conc',
                                   'concreteness ratings', variable),
                 variable = ifelse(variable == 'SER',
                                   'sensory experience ratings (SER)', variable),
                 variable = ifelse(variable == 'AOA',
                                   'age-of-acquisition ratings', variable),
                 variable = ifelse(variable == 'ARC',
                                   'ARC (semantic neighborhood density)', variable),
                 variable = ifelse(variable == 'SER:ARC_z',
                                   'ARC * SER interaction', variable),
                 variable = ifelse(variable == 'logletter',
                                   'log letter frequency', variable))

# Show tibble:

fixefs
```

Make a coefficient plot of this:

```{r, fig.width = 5, fig.height = 8}
# Setup the plot:

coef_p <- fixefs %>%
  ggplot(aes(x = reorder(variable, Estimate), y = Estimate,
             ymin = Q2.5, ymax = Q97.5))

# Add geoms:

coef_p <- coef_p + 
  geom_point(shape = 15) +
  geom_hline(aes(yintercept = 0), linetype = 2) + 
  geom_errorbar(width = 0.1)

# Add cosmetics:

coef_p <- coef_p +
  ylab('Standardized coefficient') +
  coord_flip() +
  theme_minimal() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_text(margin = margin(t = 15, b = 0,
                                                    r = 0, l = 0),
                                    face = 'bold',
                                    size = 16),
        axis.text.y = element_text(face = 'bold', size = 14))

# Show plot:

coef_p

# Save:

ggsave(plot = coef_p, filename = '../figures/main_coefficients.pdf',
       width = 9, height = 5.5)
```

Create the predictions for POS categories:

```{r}
# Extract posteriors

POS_posts <- posterior_samples(all_mdl)

# Add posterior samples of the respective coefficients

functions <- POS_posts$b_Intercept
adjs <- POS_posts$b_Intercept + POS_posts$b_POS_simpleAdjective
advbs <- POS_posts$b_Intercept + POS_posts$b_POS_simpleAdverb
interj <- POS_posts$b_Intercept + POS_posts$b_POS_simpleInterjection
nouns <- POS_posts$b_Intercept + POS_posts$b_POS_simpleNoun
verbs <- POS_posts$b_Intercept + POS_posts$b_POS_simpleVerb

# Create tibble:

preds <- tibble(POS = c('Function',
                        'Adverb',
                        'Noun',
                        'Adjective',
                        'Verb',
                        'Interjection'),
                Estimate = c(mean(functions),
                             mean(advbs),
                             mean(nouns),
                             mean(adjs),
                             mean(verbs),
                             mean(interj)),
                Q2.5 = c(quantile(functions, 0.025),
                         quantile(advbs, 0.025),
                         quantile(nouns, 0.025),
                         quantile(adjs, 0.025),
                         quantile(verbs, 0.025),
                         quantile(interj, 0.025)),
                Q97.5 = c(quantile(functions, 0.975),
                          quantile(advbs, 0.975),
                          quantile(nouns, 0.975),
                          quantile(adjs, 0.975),
                          quantile(verbs, 0.975),
                          quantile(interj, 0.975)))

# Show:

preds
```

Make a prediction plot of this:

```{r, fig.width = 5, fig.height = 8}
# Setup the plot:

POS_p <- preds %>%
  ggplot(aes(x = reorder(POS, Estimate), y = Estimate,
             ymin = Q2.5, ymax = Q97.5))

# Add geoms:

POS_p <- POS_p + 
  geom_point(shape = 15, size = 2) +
  geom_errorbar(width = 0.1)

# Add cosmetics:

POS_p <- POS_p +
  ylab('Estimated iconicity') +
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(face = 'bold',
                                   size = 12, angle = 45, hjust = 1),
        axis.title.y = element_text(margin = margin(t = 0, b = 0,
                                                    r = 15, l = 0),
                                    face = 'bold', size = 16))

# Show plot:

POS_p

# Save:

ggsave(plot = POS_p, filename = '../figures/POS_preds.pdf',
       width = 7, height = 7)
```

This completes this analysis.